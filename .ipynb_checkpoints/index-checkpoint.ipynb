{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ba807a",
   "metadata": {},
   "source": [
    "# House Sales Analysis in NorthWestern county"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586146da",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### a) Introduction\n",
    "\n",
    "House sales began in 1890s in the United States and since then its been growing all over the world and agencies started to form to enhance and ease the house selling process.Last year the revenue was estimated to be $4.25M with prospects of growth as time goes by. House sales are mainly influenced by the number of bedrooms, bathrooms, the year built, square footage and whether renovations are done or not among other factors.\n",
    "\n",
    "In this case the Northwest agencies aim to address the need of providing homeowners with accurate and actionable advice on how various house features can potentially increase the estimated value of their properties and by what amount. By understanding the relationship between various house factors and house prices, the agencies can be able to guide homeowners in making informed decisions, which will ultimately lead to maximization of return on their investment which will enable them sell their homes at optimal prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76fc9d1",
   "metadata": {},
   "source": [
    "### b) Problem statement\n",
    "\n",
    "The real estate industry faces the challenge of providing homeowners with reliable information about how various home renovation factors impact the estimated value of their homes. Our project addresses this problem by utilizing data analysis and regression modeling to identify key factors that affect house prices in a northwestern county. By understanding these factors, we can provide recommendations and insights to stakeholders on how to effectively advise homeowners on renovations that can potentially increase the value of their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db766d2",
   "metadata": {},
   "source": [
    "### c) Main Objective\n",
    "\n",
    "The main objective of this project is to develop a predictive model that estimates house prices based on various features such as the number of bedrooms and bathrooms, square footage, and year built. By building a regression model, we aim to accurately predict house prices and provide stakeholders with valuable insights into the factors driving price fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73317e",
   "metadata": {},
   "source": [
    "### d) Metric of success\n",
    "\n",
    "The success of our project will be evaluated based on the model's performance in predicting house prices. We will use evaluation metrics such as the coefficient of determination (R-squared), mean squared error(MSE) and root mean square error (RMSE) to assess the model's accuracy. A higher R-squared value and lower RMSE indicate a more successful model in capturing the variations in house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89fb339",
   "metadata": {},
   "source": [
    "### e) Specific Objectives\n",
    "\n",
    "- Explore and preprocess the King County House Sales dataset, including handling missing values, transforming features, and encoding categorical variables.\n",
    "- Perform exploratory data analysis to gain insights into the distribution and relationships between different features and the target variable.\n",
    "- Conduct feature selection to identify the most influential factors that affect house prices and eliminate irrelevant or redundant features.\n",
    "- Build multiple linear regression models with different combinations of features and evaluate their performance using appropriate metrics.\n",
    "- Interpret the results of the final regression model, including the coefficients of the selected features and their implications on house prices.\n",
    "- Provide recommendations to stakeholders based on the insights gained from the modeling process, suggesting specific renovation factors that homeowners can focus on to increase the estimated value of their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace55e70",
   "metadata": {},
   "source": [
    "##  2. Data Understanding\n",
    "\n",
    "The data used for this project is the King County House Sales dataset. The dataset contains information on house sales in a northwestern county, including various features such as the number of bedrooms and bathrooms, square footage, location, and other relevant details.The dataset is suitable for the project as it provides comprehensive information about house sales and house features, which allows for analysis and modeling to understand the relationship between these features and the sale prices of the houses.\n",
    "\n",
    "The dataset consists of a substantial number of records, with each record representing a house sale. It includes information on multiple features, such as bedrooms, bathrooms, square footage, and more. To gain insights into the dataset, we will present descriptive statistics for all the features used in the analysis. These statistics will include measures of central tendency  and dispersion to provide an overview of the distribution and variability of the data.\n",
    "\n",
    "The features included in the analysis are selected based on their relevance and potential impact on house prices. Features such as the number of bedrooms and bathrooms, square footage, and location are commonly considered important factors affecting house prices. By including these features in the analysis, we aim to capture the significant aspects that contribute to the variation in house prices and provide valuable insights to homeowners seeking advice on home renovations.\n",
    "\n",
    "Even though this dataset provides a rich source of information, it also has limitations which include absence features that could also influence house prices  such as proximity to public transportation, missing data in certain columns, outliers and the inherent complexity of real estate market dynamics that cannot be fully captured by the dataset alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70002bba",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "This process involves cleaning, transforming, and organizing the data to ensure its suitability for analysis and modeling. \n",
    "\n",
    "- Importing relevant libraries\n",
    "- Loading the dataset and checking it contains\n",
    "- Dealing with missing data\n",
    "- Checking and removing duplicates\n",
    "- Handling outliers\n",
    "- Feature scaling and normalization using z-scores\n",
    "- Encoding categoriacl variables using one-hot encoding\n",
    "- Exploring the dataset to identify opportunities for creating new features that may enhance the predictive power of the model \n",
    "- Splitting the dataset into training and test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d83ca",
   "metadata": {},
   "source": [
    "###  Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96aec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3c243",
   "metadata": {},
   "source": [
    "###  Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23002af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the house dataset and previewing the last five outputs to check what each column contains\n",
    "data = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a2571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting an overview of the dataset, including the number of non-null values and the data types of each column\n",
    "print(data.info())\n",
    "# getting the number of rows and columns in the data.\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db534d",
   "metadata": {},
   "source": [
    "The dataset has 21597 rows and 21 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the datatypes of each columns\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating summary statistics for the numerical columns in the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c81a34",
   "metadata": {},
   "source": [
    "Most houses have an average of 3 bedrooms,2 bathrooms and were built between 1970 and 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e05ac2",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09c126",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "We will check to see which columns have missing values and fill them using .fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b1a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the proportion of missing values per column\n",
    "data.isna().sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33806539",
   "metadata": {},
   "source": [
    "Three columns have missing values but we will only work with waterfront since it will be used in analysis and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4520cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since waterfront has missing values, we first check the value counts\n",
    "data['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing values in the 'waterfront' column with the string 'NO'\n",
    "data['waterfront'] = data['waterfront'].fillna('NO')\n",
    "# getting an overview of the dataset after filling the missing values in Waterfront\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9011e",
   "metadata": {},
   "source": [
    "We filled the missing values in waterfront instead of removing them since we want each column to have the same number of rows.\n",
    "we can now see that the waterfront column has the same values as the other columns we will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12095c3",
   "metadata": {},
   "source": [
    "### Dropping Columns\n",
    "\n",
    "Dropping columns that will not be used during modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns that we will not be using in data analysis.\n",
    "columns_to_drop = ['date', 'view', 'sqft_above', 'sqft_basement', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if the columns have been dropped.\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965fdc8",
   "metadata": {},
   "source": [
    "The columns have been dropped and we remaining with 11 columns that we will be working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b12c44",
   "metadata": {},
   "source": [
    "### Handling duplicates\n",
    "\n",
    "We will check if there are any duplicated values, drop them incase they are there and keep the first value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there are any duplicates\n",
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33949b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the sum of duplicated ids\n",
    "data['id'].duplicated().sum()\n",
    "# dropping the duplicated values and keeping the first in id column\n",
    "data = data.drop_duplicates(subset='id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now checking the if there are any duplicated values\n",
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6635cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of the data to see if duplicated values have been dropped.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c611af",
   "metadata": {},
   "source": [
    "As we can see the entry values changed from 21597 to 21420 meaning duplicated values were dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74700120",
   "metadata": {},
   "source": [
    "### Handling outliers\n",
    "\n",
    "Firstly we will identify outliers, get visualizations when there are outliers, we will then go ahead and remove them and get visualizations to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the numerical columns in the dataset\n",
    "numeric_columns = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'yr_built', 'floors']\n",
    "\n",
    "# Calculating z-scores for the numerical columns\n",
    "z_scores = (data[numeric_columns] - data[numeric_columns].mean()) / data[numeric_columns].std()\n",
    "\n",
    "# defining a threshold for identifying outliers\n",
    "threshold = 2\n",
    "\n",
    "# Find the indices of outliers for each column\n",
    "outlier_indices = (z_scores > threshold).any(axis=1)\n",
    "\n",
    "# Extract the outlier rows from the dataset\n",
    "outliers = data[outlier_indices]\n",
    "\n",
    "# Plotting the outliers\n",
    "for column in numeric_columns:\n",
    "    plt.figure()\n",
    "    plt.boxplot(data[column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outlier rows from the dataset\n",
    "data_cleaned = data[~outlier_indices]\n",
    "\n",
    "# Reset the index of the cleaned dataset\n",
    "data_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Plot histograms of the cleaned dataset\n",
    "data_cleaned[numeric_columns].hist(bins=20, figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot scatterplots of price against other numeric columns\n",
    "sns.pairplot(data_cleaned, x_vars=['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot'], y_vars='price', height=5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ccc42",
   "metadata": {},
   "source": [
    "### One-Hot encoding\n",
    "\n",
    "First, we check for categorical columns, then get the value counts and lastly perform encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02409ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring categorical variables,using value_counts() to get the count of each unique value in a column \n",
    "# using describe() to get summary statistics for categorical columns.\n",
    "for column in categorical_columns:\n",
    "    value_counts = data[column].value_counts()\n",
    "    print(f\"Value counts for {column}:\\n{value_counts}\\n\")\n",
    "\n",
    "# Summary statistics for categorical columns\n",
    "print(data[categorical_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f125b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding to convert categoriacl values into binary'\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a456e",
   "metadata": {},
   "source": [
    " ### Feature scaling and normalization using z-scores\n",
    "This is done to numerical features to standardize their values and ensure they are on a similar scale and  helps prevent any bias or undue influence that may arise from differences in the magnitude of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Computing the z-scores for the numerical features only\n",
    "data_numeric = data[numeric_columns]\n",
    "data_numeric = (data_numeric - data_numeric.mean()) / data_numeric.std()\n",
    "\n",
    "# Combining the encoded categorical features with the transformed numerical features\n",
    "data_encoded = pd.concat([data_encoded, data_numeric], axis=1)\n",
    "\n",
    "# Checking the updated dataset\n",
    "print(data_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965ca33",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n",
    "\n",
    "Correlation analysis is a statistical technique used to measure the strength and direction of the linear relationship between two or more variables. It helps identify the degree of association between variables and provides insights into their interdependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82363df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_matrix = data_cleaned[numeric_columns].corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plotting the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5f76d",
   "metadata": {},
   "source": [
    "## Regression modelling\n",
    "\n",
    "- To perform regression modeling, we will split the dataset into features (X) and target variable (y), and then split them into training and testing sets. We will use the LinearRegression model from scikit-learn library to build the regression model.\n",
    "- We are using regression since it provides  more rigorous and quantitative approach to understanding the relationships between variables in the data.\n",
    "- Regression coefficients provide numerical values that represent the magnitude and direction of the relationship between variables. This allows for precise interpretation and comparison of the impact of different variables on the target variable.\n",
    "- Regression models can account for the effects of other variables and control for confounding factors. By including multiple variables in the model, we can assess the unique contribution of each variable while controlling for the influence of other factors.\n",
    "- Statistical analyses allow for model evaluation using performance metrics like R-squared, MSE, RMSE These metrics provide objective measures of model fit and predictive accuracy, enabling comparison between different models to identify the most effective one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4363f5d",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "We going to create a simple regression model without using any modifications to establish a baseline performance metric that other models can compare aganaist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7156ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the target variable and features\n",
    "target = 'price'\n",
    "features = ['sqft_living']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the baseline linear regression model\n",
    "baseline_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the MSE\n",
    "print(\"\\nBaseline Regression Model Evaluation:\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print('Baseline Model MSE:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80206701",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) is a measure of the average squared difference between the predicted sale prices and the actual sale prices in the dataset. The MSE in this case is 61857052064.47349, which indicates the average squared difference between the predicted and actual sale prices is approximately $61857052064.47349\n",
    "\n",
    "The R-squared value of 0.49 indicates that approximately 49% of the variability in the sale prices can be explained by the independent variables sqft_living in the model. This means that the model accounts for 49% of the variance in the target variable, with the remaining 51% being attributed to other factors not included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b7787",
   "metadata": {},
   "source": [
    "### Second Model using Muliple linear regression \n",
    "\n",
    "We going to use three variables and see the difference between the basic linear regression and multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40b95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating the feature matrix X and the target variable y\n",
    "X = data[['bedrooms', 'bathrooms', 'sqft_living']]\n",
    "y = data['price']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the coefficients\n",
    "coefficients = model.coef_\n",
    "for feature, coefficient in zip(X.columns, coefficients):\n",
    "    print(f'{feature}: {coefficient}')\n",
    "\n",
    "# Print the mean squared error and R-squared score\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc069481",
   "metadata": {},
   "source": [
    "The coefficient for the bathrooms is 6932.45, suggesting that, on average, each additional bathroom is associated with an increase in the predicted sale price by $6,932.45, holding all other variables constant.\n",
    "\n",
    "The coefficient for the sqft_living variable is 311.57, indicating that, for each additional square foot of living area, the predicted sale price increases by $311.57, assuming other variables remain constant.\n",
    "\n",
    "The MSE in this case is 59825974041.54, which indicates the average squared difference between the predicted and actual sale prices is approximately $59,825,974,041.54.\n",
    "\n",
    "The R-squared value of 0.5059 indicates that approximately 50.59% This means that the model accounts for 50.59% of the variance in the target variable, with the remaining 49.41% being attributed to other factors not included in the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c254a",
   "metadata": {},
   "source": [
    "### Third Model using polynomial Transformation\n",
    "\n",
    "This model is introduced to build on the baseline model, it will incorporate additional features such as polynomial transformation to capture non linear relationships to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting features and splitting data into train and test\n",
    "X = data_encoded.drop(['price'], axis=1)\n",
    "y = data_encoded['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating new feature using polynomial transformation\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "\n",
    "# Creating a new model using the selected features\n",
    "model_two = LinearRegression()\n",
    "model_two.fit(X_poly_train, y_train)\n",
    "\n",
    "# Transforming  the test features\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "# Making predictions on the test data\n",
    "y_pred = model_two.predict(X_poly_test)\n",
    "\n",
    "# Calculating the mean squared error (MSE) and Rsquared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the MSE\n",
    "print(\"\\nModel2 Regression Model Evaluation:\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print('Model2 MSE:', mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a58fa",
   "metadata": {},
   "source": [
    "The improvements in R^2 indicate that the new model explains a larger portion of the variance in the target variable compared to the other models. This means that the new model provides a better fit to the data and has the potential to make more accurate predictions. The reduction in MSE implies that the new model has smaller prediction errors, which can be valuable for stakeholders in terms of making informed decisions or pricing properties more accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d66c7",
   "metadata": {},
   "source": [
    "### Regression Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a0255",
   "metadata": {},
   "source": [
    "We identified that sqft_living and bathrooms have the strongest relationship with price.\n",
    "\n",
    "For every unit increase in 'sqft_living', the predicted sale price increases by a certain coefficient value. For example, if the coefficient for 'sqft_living' is 100, it means that for every additional square foot of living area, the sale price is expected to increase by $100.\n",
    "\n",
    "Similarly, for every additional bathroom in the property, the predicted sale price increases by a specific coefficient value. For instance, if the coefficient for 'bathrooms' is 50, it indicates that each additional bathroom is associated with a $50 increase in the sale price. By identifying the strong relationships between these features and sale prices, stakeholders can gain valuable insights into the factors that significantly influence property values.\n",
    "\n",
    "For buyers and sellers, understanding the impact of 'sqft_living' and 'bathrooms' on sale prices can help in making informed decisions. Buyers can consider the trade-off between the size of the living area and the price they are willing to pay. Sellers, on the other hand, can leverage this information to determine an appropriate listing price for their property based on its size and bathroom count.\n",
    "\n",
    "Property developers and investors can also benefit from these results. Developers can focus on constructing properties with larger living areas and more bathrooms to cater to the demand for such features, as they are likely to command higher sale prices. Investors can consider these features when evaluating potential investment properties, as they play a significant role in determining the property's value appreciation over time.\n",
    "\n",
    "Buyers consider the impact of living area and bathroom count on the sale price when searching for properties. Determine the desired size and number of bathrooms based on personal preferences and budget constraints.\n",
    "Sellers: Take into account the size of the living area and the number of bathrooms when pricing the property. Highlight these features in the property listing to attract potential buyers.\n",
    "Developers: Focus on constructing properties with larger living areas and multiple bathrooms to appeal to buyers looking for spacious and well-equipped homes.\n",
    "Investors: Consider the influence of living area and bathroom count when evaluating investment opportunities. Properties with larger living areas and more bathrooms may have higher potential for value appreciation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86657503",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Here we will be using Exploratory Data Analysis to allow shareholders understand the value and success of how different features affect prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47c467",
   "metadata": {},
   "source": [
    "#### Histogram\n",
    "\n",
    "The histogram plot will provide a visual representation of the distribution of house prices in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c050ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "# Visualize the distribution of the target variable (price)\n",
    "sns.histplot(data=data_cleaned, x='price', kde=True)\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059eed8",
   "metadata": {},
   "source": [
    "This plot allows stakeholders to understand the range and frequency of different price levels. The justification for this plot is that it helps stakeholders gain insights into the overall distribution of house prices, which can be useful for understanding the market dynamics and identifying any potential outliers or skewed distributions. By visualizing the distribution, stakeholders can make informed decisions about pricing strategies and identify areas of focus for their analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f63995",
   "metadata": {},
   "source": [
    "#### Box plot\n",
    "\n",
    "We will be using a measure of central tendecy (median) to give shareholders a better understanding of how the house condition affects the sales price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd192a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a box plot of condition and price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='condition', y='price', data=data_cleaned)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Sale Price')\n",
    "plt.title('Distribution of Sale Prices by Condition')\n",
    "\n",
    "# Adding median to price\n",
    "medians = data.groupby('condition')['price'].median()\n",
    "    \n",
    "plt.show()\n",
    "print(medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886ba50",
   "metadata": {},
   "source": [
    "Condition of the house influences the house price. Properties with very good condition have the highest median sale price  while those with poor condition having the least sale price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de6427",
   "metadata": {},
   "source": [
    "#### Line Plot\n",
    "\n",
    "Using line plot to demonstrate trends of sales as the years go by to enable us see the trendsin properties over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d614ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate average sale price for each year\n",
    "avg_price_by_year = data_cleaned.groupby('yr_built')['price'].mean()\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=avg_price_by_year.index, y=avg_price_by_year.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year Built')\n",
    "plt.ylabel('Average Sale Price')\n",
    "plt.title('Trend of Sale Prices Over Time')\n",
    "\n",
    "# Adjust x-axis ticks and labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d7b7e",
   "metadata": {},
   "source": [
    "The line plot illustrates the trend of sale prices over time, specifically how prices have evolved as the years go by.\n",
    "We can see a clear upward trend from 1960, indicating that sale prices have generally increased over the years. This suggests that properties built in more recent years tend to have higher sale prices compared to older properties.\n",
    "\n",
    "The increasing trend of sale prices over time can be attributed to several factors such as inflation and the general rise in the cost of living contribute to the overall increase in property prices and a higher demand for newer and more modern properties, which drives up their price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
